{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats_import = pd.read_csv('All_Data_2006_2016.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAECCAYAAAD6oXArAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFCZJREFUeJzt3X+Q7Xdd3/Hn6+aSkCCC0Gl2SJp7CRixKRGj3Fopuhpp\nUpFEhdqg1CntkFZpYLTTSY3MZP/pDOOPIoK2WkJGqJkMRMREUUmGnjgM0kQkTQhJkxlLfpLbsd4W\noyGEy7t/nHNlv5e7e7+753v2+zm7z8fMmez3e86+89q9u9/3fj+fz/d7UlVIknTMvrEDSJLaYmOQ\nJHXYGCRJHTYGSVKHjUGS1GFjkCR12BgkSR02BklSx/6xAxwvyUuAtwLPBz5WVf955EiStKek1Suf\nkwT4jar68bGzSNJesvChpCTXJjmc5K7j9l+S5L4k9ye56rjnXgP8LvCRReeTJHUt/IwhyT8EngDe\nV1UXzPbtA+4HLgIeA+4ALq+q+4773N+tqh9YaEBJUsfC5xiq6uNJDhy3+xDwQFU9CJDkBuAy4L4k\n3w38MHAa8HuLzidJ6hpr8vks4OF1248wbRZU1W3AbZt9cpI2J0YkqXFVlZO9ZmmXq1ZV849rrrlm\n9AzmNKc5zXjs0ddYjeFR4Jx122fP9kmSRrZTjSGzxzF3AC9OciDJqcDlwE1bKbi2tsZkMhkuoSTt\nUpPJhLW1td6v34nlqtcDnwDOS/JQkjdW1VHgSuCjwD3ADVV171bqrq2tsbq6OnjeIbWe7xhzDsuc\nw1qGnK1nXF1d3VJjaPYCt80kqWXMLUljSkLt5slnSdJiLG1jcI5BkvrZ6hyDQ0nSFqysHOTw4QcH\nqXXmmQd4/PHPDVJL6qPvUJKNQdqC6b0dh/rZy5bWlkvzco5BkrQtS9sYnGOQpH6cY5AWyKEkLTOH\nkiRJ22JjkEZzGkkGe6ysHBz7C9Iu4VCStAVDDyUNV2taz98LbWbXDyU5+SxJ/Tj5LC2QZwxaZrv+\njEGStBg2BklSh41BktRhY5AkdSxtY3BVkiT146okaZ0hb5P9Va5K0nLyttsSQy8vhWEP5jYG7SyX\nq0qStsXGIEnqsDFIu4Y35dMwnGPQrrbX5hics9Bmdv0cg8tVJakfl6tK63jGMF89f892l11/xiBJ\nWgwbgySpw8YgSeqwMUiSOmwMkqQOG4MkqcPGIEnqsDFIkjqWtjF45bMk9eOVz1pqbb+xDnjls5aZ\nb9SjpdT2LSyGrtdytmk9f892F2+JIUnaFhuDJKnDxiBJ6rAxSJI6bAySpA4bgySpw8YgaQOnkWSQ\nx8rKwbG/GG2B1zGoKV7HsFvreU1EC7yOQZK0LTYGSVLH0jYGb6InSf14Ez0tNecYdms95xha4ByD\nJGlbbAySpA4bgySpw8YgSeqwMUiSOmwMkqQOG4MkqcPGIEnqsDFIkjpsDJKkDhuDJKnDxiBJ6rAx\nSJI6bAya28rKwcHeAlLS+LzttuY27K2yW7519ND1Ws42dD1vu92Cvrfd3r8TYbYqyWXAq4FnA++t\nqltGjiRJe0bTZwxJngv8fFW96bj9njE0xDOGFmq1Xs8zhhY09UY9Sa5NcjjJXcftvyTJfUnuT3LV\nCT71bcCv7ERGSdLUTk0+XwdcvH5Hkn3Au2f7zwden+Ql655/O/CRqrpzhzJKktihxlBVHweOHLf7\nEPBAVT1YVU8DNwCXASS5ErgIeF2SK3YioyRpaszJ57OAh9dtP8K0WVBV7wLetdknr62t/c3Hq6ur\nrK6uDh5Q0lBOG3Q58plnHuDxxz83WL3dajKZMJlMtvx5Ozb5nOQAcHNVXTDbfi1wcVVdMdt+A3Co\nqt7So5aTzw1x8rmFWq3XGz6bx4Cta2ryeQOPAues2z57tk+SNKKdbAyZPY65A3hxkgNJTgUuB27q\nW2xtbW1bp0iStNdMJpPO8PvJ7MhQUpLrgVXg+cBh4Jqqui7JPwZ+iWmDuraq3t6znkNJDXEoqYVa\nrddzKKkFfYeSmr7AbSM2hrbYGFqo1Xo9G0MLlmGOQZLUoKVtDM4xSFI/Tc4xDM2hpLY4lNRCrdbr\nOZTUAoeSJEnbYmOQJHXYGCRJHUvbGJx8lqR+FjL5nOSlVXX3HLkG5eRzW5x8bqFW6/WcfG7B0JPP\nv5rk9iQ/meQ5c2aTJDWsV2OoqlcCPwb8HeBTSa5P8qqFJpMkjWJL1zEkOQX4QeCXgS8wPT+8uqo+\ntJh4G+ZwKKkhDiW1UKv1eg4ltWDQoaQkFyR5B3Av8L3Aa6rqm2cfv2OupNvk5LMk9bOoyefbgPcA\nN1bVk8c998+q6v1bzDkXzxja4hlDC7Var+cZQwsGvbtqkq8Dnqyqo7PtfcAzq+qv5066DTaGttgY\nWqjVej0bQwuGXpV0K3D6uu0zZvskSbtM38bwzKp64tjG7OMzFhNJkjSmvo3hr5JceGwjybcBT27y\n+oVz8lmS+lnU5PPLgRuAx5gOFq4A/7SqPrW9mPNxjqEtzjG0UKv1es4xtGDwt/ZM8gzgm2ab/7Oq\nnp4j31xsDG2xMbRQq/V6NoYWLKIxfCdwENh/bF9VvW+7AedhY2iLjaGFWq3XszG0oG9j2H+yF8yK\nvR94EXAncHS2u4BRGoMkaXF6NQbg24G/65/pkrT79V2V9BmmE87aBVZWDpJksIek3aXvGcPfAj6b\n5HbgqWM7q+rShaTSQh0+/CDDj0VL2i36Noa1RYbYjrW1NVZXV1ldXR07iiQ1bTKZbOm6r62sSjoA\nfGNV3ZrkDOCUqvrLbaWck6uS5jPsKiJoffVKu/VazjZ0PVcltWDo226/CbgR+LXZrrOAD28/niSp\nVX0nn98MvILpm/NQVQ8Af3tRoSRJ4+nbGJ6qqi8d20iyn2HPCyVJjejbGG5LcjVw+uy9nj8I3Ly4\nWJKksfS9id4+4F8C/4jpLNIfAu8ZawbYyef5OPncSr2Wsw1dz8nnFgx+r6SW2BjmY2NopV7L2Yau\nZ2NowdD3SvpfnOBftarO3UY2SZrTaYNddX/mmQd4/PHPDVJrt9jKvZKOeSbwT4DnDR+nPy9wk/ay\npxjqDOTw4d1/5f7CLnD7mk9MPlVV37atT56TQ0nzcSiplXotZxu6XtvZ9srxZOihpAvXbe5jegbR\n92xDkrRE+h7cf3Hdx18GPgf8yOBpJEmjc1XSHuRQUiv1Ws42dL22s+2V48nQQ0k/vdnzVfUf+waT\nJLVtK6uSXg7cNNt+DXA78MAiQkmSxtP3yuc/Al597DbbSZ4N/F5VfdeC822Ux6GkOTiU1Eq9lrMN\nXa/tbHvleDLobbeBM4Evrdv+0myfJGmX6TuU9D7g9iS/Pdv+QeA3FhNJkjSmrbyD24XAK2ebf1RV\nn15YqpNncShpDg4ltVKv5WxD12s72145ngw9lARwBvCFqnon8EiSF247nSSpWX3f2vMa4CrgZ2a7\nngH810WFkiSNp+8Zww8BlwJ/BVBVjwHPXlSoPtbW1rZ0UyhJ2qsmkwlra2u9X993uertVXUoyZ9W\n1YVJngX8cVVdsP2o2+ccw3ycY2ilXsvZhq7Xdra9cjwZeo7hA0l+DXhukjcBtwL/ZZ6AkqQ2bWVV\n0qtY99aeVXXLIoOdJItnDHPwjKGVei1nG7pe29n2yvFksLf2THIKcGtVfc9Q4eZlY5iPjaGVei1n\nG7pe29n2yvFksKGkqjoKfCXJcwZJJklqWt8rn58A7k5yC7OVSQBV9ZaFpJIkjaZvY/jQ7CFJ2uU2\nnWNIck5VPbSDeXpxjmE+zjG0Uq/lbEPXazvbXjmeDDXH8OF1BX9r7lSSpOadrDGs7yznLjKIJKkN\nJ2sMtcHHkqRd6mRzDEeZrkIKcDrw18eeAqqqvn7hCU+cyzmGOTjH0Eq9lrMNXa/tbHvleNJ3jmHT\nVUlVdcpwkSRJy2Ar78cgSdoDbAySpA4bgySpo7nGkOSFSd6T5ANjZ2nJyspBkgzykKTN9L7t9k5L\n8oGq+pENnttzq5KGXUnU9gqRdrMNXa/lbEPXazvbXjmeDP1GPfMEuTbJ4SR3Hbf/kiT3Jbk/yVWL\nziFJ6mcnhpKuAy5evyPJPuDds/3nA69P8pLjPs8xD0kawcIbQ1V9HDhy3O5DwANV9WBVPQ3cAFwG\nkOR5Sf4T8DLPJCRp5/W97fbQzgIeXrf9CNNmQVX9BfATJyuwtrb2Nx+vrq6yuro6aEBJWnaTyYTJ\nZLLlz9uRyeckB4Cbq+qC2fZrgYur6orZ9huAQ33f+MfJ57mrDVhr6HotZxu6XsvZhq7Xdra9cjxp\nZvJ5A48C56zbPnu2T5I0sp1qDKE7mXwH8OIkB5KcClwO3LRDWSRJm9iJ5arXA58AzkvyUJI3VtVR\n4Ergo8A9wA1Vde9W6q6trW1r7EyS9prJZNKZlz2ZZi9w24xzDHNXG7DW0PVazjZ0vZazDV2v7Wx7\n5XjS+hyDJKlRNgZJUsfSNgbnGCQN47TBblCZhJWVg2N/QV/DOYZdyjmG3Viv5WxD19tb2Vo9PjnH\nIEnaFhuDJKljaRuDcwyS1I9zDLuUcwy7sV7L2Yaut7eytXp8co5BkrQtNgZJUoeNQZLUsbSNwcln\nSW1q74I5J593KSefd2O9lrMNXc9s89Qb6njn5LMkaVtsDJKkDhuDJKnDxiBJ6ljaxuCqJEnqx1VJ\nu5SrknZjvZazDV3PbPPUc1WSJGlUNgZJUoeNQZLUYWOQJHXYGCRJHUvbGFpfrrqycnDQG2lJ0na5\nXLURwy4vhb2zPK/lbEPXaznb0PXMNk89l6tKkkZlY5AkddgYJEkdNgZJUoeNQZLUYWOQJHXYGCRJ\nHUvbGFq/wE2SWuEFbo3wArcWarVer+VsQ9cz2zz1vMBNkjQqG4MkqcPGIEnqsDFIkjpsDJKkDhuD\nJKnDxiBJ6rAxSJI6bAySpA4bgySpY//YAVpx5MgRvvjFL44dQ5JGt7SNYW1tjdXVVVZXV+eudeTI\nEV7wggMkz5o/GPD00385SB1JGsJkMtnSTUe9iR7w+c9/nhe96EKefPLzA1X8D8DbaPfGXC3fNKzl\nbEPXaznb0PXMNk89b6InSRqVjUGS1GFjkCR12BgkSR02BklSh41BktRhY5AkddgYJEkdNgZJUoeN\nQZLUYWOQJHXYGCRJHTYGSVKHjUGS1GFjkCR12BgkSR3NvYNbkjOAXwWeAm6rqutHjiRJe0qLZww/\nDHywqv4VcOnYYeYzGTtAT5OxA/Q0GTtAT5OxA/Q0GTtAT5OxA/QwGTvAoBbeGJJcm+RwkruO239J\nkvuS3J/kqnVPnQ08PPv46KLzLdZk7AA9TcYO0NNk7AA9TcYO0NNk7AA9TcYO0MNk7ACD2okzhuuA\ni9fvSLIPePds//nA65O8ZPb0w0ybA0zfPFWStIMW3hiq6uPAkeN2HwIeqKoHq+pp4Abgstlzvw28\nLsmvADcvOp8kqStVtfj/SXIAuLmqLphtvxa4uKqumG2/AThUVW/pWW/xoSVpF6qqk47ENLcqqY8+\nX5gkaXvGWpX0KHDOuu2zZ/skSSPbqcYQuhPJdwAvTnIgyanA5cBNO5RFkrSJnViuej3wCeC8JA8l\neWNVHQWuBD4K3APcUFX3LjqLJOnkdmJV0o9W1Quq6rSqOqeqrpvt//2q+qaq+saqevtW6yb5liR/\nnOTTSW5P8u3Dpx9GkiuT3Jvk7iRb/lp3UpJ/m+QrSZ43dpYTSfJzs+/lnUl+K8nXj53pmE2uzWlG\nkrOTfCzJPbOfx14LPsaSZF+SP03S7IhCkuck+eDs5/KeJH9/7EwnkuSnknwmyV1JfnM2WnNCLV75\n3NfPAddU1bcC1wA/P3KeE0qyCrwGeGlVvRT4hXETbSzJ2cCrgAfHzrKJjwLnV9XLgAeAnxk5D3DS\na3Na8mXgp6vqfOAfAG9uNOcxbwU+O3aIk3gn8JGq+mbgW4DmRj+SvIDpKM2Fs9Wh+5kO4Z/QMjeG\nrwDPmX38XNqdvP4J4O1V9WWAqvrzkfNs5h3Avxs7xGaq6taq+sps85N89WLIsW12bU4zqurxqrpz\n9vETTA9iZ42b6sRmf6h8P/CesbNsZHbG+sp1IyFfrqovjBxrI6cAz0qyHzgDeGyjFy5zY/gp4BeS\nPMT07KGJvxxP4Dzgu5J8Msl/a3XIK8mlwMNVdffYWbbgXwC/P3aImbP46q1cAB6h0QPuMUkOAi8D\n/vu4STZ07A+Vlq9beiHw50mumw15/XqS08cOdbyqegz4ReAhpn9E/9+qunWj1zd9HUOSW4Az1+9i\n+kPys8D3AW+tqg8neR3wXqbDIDtuk5xvY/o9/oaq+o4kLwc+AJy78ylPmvNqut+/0a4V2ezfvapu\nnr3mZ4Gnvfvu9iT5OuBGpr9DT4yd53hJXg0crqo7Z8OxrV67tB+4EHhzVf1Jkl8C/j3T4e1mJHku\n0zPYA8D/A25M8qMb/f403RiqasMDfZL3V9VbZ6+7Mcm1O5es6yQ5/zXwodnr7phN7D6/qv7PjgWc\n2Shnkr8HHAT+R5IwHZ75VJJDVfW/dzAisPn3EyDJP2c6xPC9OxKon6W5Nmc2lHAj8P6q+p2x82zg\nFcClSb4fOB14dpL3VdWPj5zreI8wPdP+k9n2jUCLCw++D/izqvoLgCQfAr4TOGFjWOahpEeTfDdA\nkouA+0fOs5EPMzuAJTkPeMYYTWEzVfWZqlqpqnOr6oVMf9i/dYymcDJJLmE6vHBpVT01dp51luna\nnPcCn62qd44dZCNVdfVsFeO5TL+XH2uwKVBVh4GHZ7/bABfR5mT5Q8B3JHnm7I+/i9hkkrzpM4aT\neBPwy0lOAb4IXDFyno1cB7w3yd1M33youR/uEyjaPXV/F3AqcMv055tPVtVPjhsJqupokn/DdNXU\nPuDaFq/NSfIK4MeAu5N8mum/9dVV9QfjJltqbwF+M8kzgD8D3jhynq9RVbcnuRH4NPD07L+/vtHr\nd+QmepKk5bHMQ0mSpAWwMUiSOmwMkqQOG4MkqcPGIEnqsDFIkjpsDJKkjv8PTItpfr2n+YcAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13853a090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "feats_import.loc[:, 'FTGD'].plot(kind='hist', bins=16)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test dropping out certain features, outdated. \n",
    "\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# performance_list = []\n",
    "# for i in range(1,21,2):\n",
    "#     if i<3:\n",
    "#         continue\n",
    "#     np.random.seed(7)\n",
    "#     X_vary = np.delete(X,(i,i+1),1)\n",
    "    \n",
    "#     def baseline_model():\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(40, input_dim=len(X_vary[0]), init='uniform', activation='relu')) \n",
    "#         # model.add(Dropout(0.3))\n",
    "#         model.add(Dense(20, activation='sigmoid'))\n",
    "#         model.add(Dense(80, activation='relu'))\n",
    "#         model.add(Dense(2*cutoff_GD+1, activation='sigmoid'))\n",
    "\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='categorical_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "#         return model\n",
    "#     estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=20, batch_size=20, verbose=0)\n",
    "    \n",
    "#     results = cross_val_score(estimator, X_vary, y, cv=kfold)\n",
    "#     print feats.columns[i:i+2]\n",
    "#     print [i, 100*results.mean(), 100*results.std()]\n",
    "#     performance_list += [i, 100*results.mean(), 100*results.std()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outdated\n",
    "\n",
    "# np.random.seed(7)\n",
    "# X_vary = X\n",
    "\n",
    "# def baseline_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(40, input_dim=len(X_vary[0]), init='lecun_uniform', activation='relu')) \n",
    "#     model.add(Dense(20, activation='relu'))\n",
    "#     model.add(Dense(2*cutoff_GD+1, activation='sigmoid'))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model\n",
    "# estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=10, verbose=0)\n",
    "\n",
    "# results = cross_val_score(estimator, X_vary, y)\n",
    "# print 100*results.mean(), 100*results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTHG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HGA</th>\n",
       "      <th>AGA</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>Odds</th>\n",
       "      <th>HP3</th>\n",
       "      <th>AP3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.760007</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.775832</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FTHG  HTHG        HS        AS       HST       AST        HF        AF  \\\n",
       "0  0.000000   0.0  0.277778  0.305556  0.222222  0.242424  0.342857  0.685714   \n",
       "1  0.333333   0.4  0.555556  0.222222  0.305556  0.151515  0.628571  0.228571   \n",
       "2  0.222222   0.0  0.361111  0.305556  0.222222  0.212121  0.314286  0.685714   \n",
       "3  0.222222   0.2  0.333333  0.444444  0.250000  0.212121  0.400000  0.571429   \n",
       "4  0.111111   0.2  0.666667  0.222222  0.361111  0.151515  0.485714  0.542857   \n",
       "\n",
       "     HC    AC        HY        AY    HR    AR       HGA       AGA      HTGD  \\\n",
       "0  0.25  0.30  0.090909  0.181818  0.00  0.00  0.309091  0.727273  0.166667   \n",
       "1  0.25  0.05  0.272727  0.000000  0.25  0.25  0.654545  0.300000  0.833333   \n",
       "2  0.15  0.25  0.000000  0.363636  0.00  0.25  0.545455  0.427273  0.500000   \n",
       "3  0.20  0.20  0.090909  0.181818  0.00  0.00  0.654545  0.381818  0.666667   \n",
       "4  0.35  0.25  0.090909  0.181818  0.00  0.00  0.581818  0.363636  0.666667   \n",
       "\n",
       "       Odds  HP3  AP3  \n",
       "0  0.656250  0.5  0.5  \n",
       "1  0.819444  0.5  0.5  \n",
       "2  0.760007  0.5  0.5  \n",
       "3  0.775832  0.5  0.5  \n",
       "4  0.819444  0.5  0.5  "
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal differential Cut-off.\n",
    "cutoff_GD = 3\n",
    "\n",
    "feats = feats_import.drop(['Season', 'Gameday', 'TID_H', 'TID_A'], axis=1).drop('FTGD', axis=1)\n",
    "feats.loc[:, 'HTGD'] = feats_import.loc[:, 'HTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)) + cutoff_GD\n",
    "\n",
    "label = feats_import.loc[:, 'FTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)) + cutoff_GD\n",
    "\n",
    "GD_min = -cutoff_GD\n",
    "GD_max = +cutoff_GD\n",
    "GD_spread = GD_max-GD_min + 1\n",
    "\n",
    "\n",
    "# Different norms because I played around with different columns\n",
    "norm = [9, 5, 36, 36, 36, 33, 35, 35, 20, 20, 11, 11, 4, 4, 1, 1, GD_spread-1, 1, 1, 1]\n",
    "#norm = [9, 5, 36, 36, 36, 33, 35, 35, 20, 20, 1, 1, GD_spread-1, 1, 1, 1]\n",
    "#norm = [9, 5, 36, 36, 36, 33, 35, 35, 20, 20, 11, 11, 4, 4, GD_spread-1, 1, 1, 1]\n",
    "\n",
    "feats = feats/norm\n",
    "\n",
    "\n",
    "ID = np.eye(GD_spread)\n",
    "\n",
    "X = feats.iloc[:3000].as_matrix()\n",
    "y_pre = map(int, label.iloc[:3000].as_matrix())\n",
    "\n",
    "y = np.array([ID[i] for i in y_pre])\n",
    "\n",
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign an expected score with probabilities\n",
    "def exp_score(x):\n",
    "    multiplier = np.array(range(-cutoff_GD, cutoff_GD+1))\n",
    "    return np.sum(np.array(x) * multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697666668395\n",
      "2784/3000 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Run Keras\n",
    "np.random.seed(7)\n",
    "\n",
    "# I tested these parameters a little bit; they seem to work nicely for know.\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=len(X[0]), init='lecun_uniform', activation='relu')) \n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*cutoff_GD+1, activation='relu'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, nb_epoch=100, batch_size=10, verbose=False)\n",
    "print model.evaluate(X, y, batch_size=10, verbose=False)[1]\n",
    "\n",
    "predictions = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03, 0.31, 0.59, 0.06, 0.0, 0.0, 0.0]\n",
      "-1.31411913025\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# Check one example.\n",
    "i=1125\n",
    "print [round(predictions[i][j], 2) for j in range(len(predictions[i]))]\n",
    "print exp_score(predictions[i])\n",
    "print label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADFhJREFUeJzt3X+s3XV9x/HXq3Q0aMP+GAkuVLy6TheME4lxJhjTgcXO\nZAMT/2AuWZx/gVFMlhmibFIWTZCYJcRliX/gj6mNJjVBdEAosuJgATuhUqVI98dFcCt/GLelYyGV\nvvbH/TZclN5zzv1+zvn0vvt8JN9wzuF7vud9U/Lsh+/9fu91EgEANrZNvQcAAIxHzAGgAGIOAAUQ\ncwAogJgDQAHEHAAK2Dz2ALa3SPqepLOH4+1NctPY4wIApucW15nbfkWS52yfJelBSdcl+f7oAwMA\nptLkNEuS54aHW7SyOudOJABYoCYxt73J9qOSjkral+RAi+MCAKYz+py5JCU5Iektts+VdLvti5I8\nvnofezerdZzBfqP3ACNd03uAUe7JVb1HGGWn/sWT9mlyzvwlB7T/RtL/Jvm7X3mdmAPAOiSZGPMW\nV7OcJ+l4kv+2fY6knZJufvm9bxz7caex/ZJ2dJ5hnvar7te3X/P/2nquzL8r6fKRxzidV+afkXT9\nmnts5JX5FX5gqv1anGb5bUlftr1JK+fgv5HkzgbHBQBMaXTMkxySdEmDWQAA68QdoM0s9R5gzpZ6\nDzBHS70HmLPX9h5gzi7tPcBpgZg3s9R7gDlb6j3AHC31HmDOXtd7gDl7R+8BTgvEHAAKIOYAUAAx\nB4ACiDkAFEDMAaAAYg4ABRBzACiAmANAAcQcAAog5gBQADEHgAKIOQAUQMwBoABiDgAFEHMAKICY\nA0ABxBwACiDmAFAAMQeAAog5ABRAzAGgAGIOAAUQcwAogJgDQAHEHAAK2Nx7AODM8IneA4xyRe7o\nPcIoV/iTvUcY4Yqp9hq9Mre9zfZ9tn9s+5Dt68YeEwAwmxYr819K+sskB21vlfQD2/ckeaLBsQEA\nUxi9Mk9yNMnB4fExSYclXTD2uACA6TX9BqjtJUkXS3q45XEBAGtrFvPhFMteSR8dVugAgAVpcjWL\n7c1aCflXknzr1HvuX/V4adgAAC/64bDNptWliV+Q9HiSW9febUejjwOAqt48bCd9dap3tbg08VJJ\nfybpMtuP2n7E9q6xxwUATG/0yjzJg5LOajALAGCduJ0fAAog5gBQADEHgAKIOQAUQMwBoABiDgAF\nEHMAKICYA0ABxBwACiDmAFAAMQeAAog5ABRAzAGgAGIOAAUQcwAogJgDQAHEHAAKIOYAUAAxB4AC\niDkAFEDMAaAAYg4ABWzuPQAwle27e08wSi537xFG8XvTe4SRdvceYO5YmQNAAcQcAAog5gBQADEH\ngAKIOQAUQMwBoIAmMbd9m+1nbT/W4ngAgNm0Wpl/UdK7Gx0LADCjJjFP8oCkX7Q4FgBgdpwzB4AC\nFnw7//5Vj5eGDQDwouVhm82CY75jsR8HABvOkl660L1/qne1PM3iYQMALFirSxP3SPpXSa+3/VPb\nf9HiuACA6TQ5zZLk/S2OAwBYH65mAYACiDkAFEDMAaAAYg4ABRBzACiAmANAAcQcAAog5gBQADEH\ngAKIOQAUQMwBoABiDgAFEHMAKICYA0ABxBwACiDmAFDAgn8H6EZ2fu8Bxnnrtb0nGOXGf9vYv5HQ\nx9J7hHGO7u49ASZgZQ4ABRBzACiAmANAAcQcAAog5gBQADEHgAKIOQAUQMwBoABiDgAFEHMAKICY\nA0ABTWJue5ftJ2w/afv6FscEAExvdMxtb5L095LeLemNkv7U9u+NPS4AYHotVuZvk3QkyVNJjkv6\nuqQrGxwXADClFjG/QNLTq54/M7wGAFiQBf888/2rHi8NGwDgRcvDNpsWMf+ZpAtXPd82vPYydjT4\nOACobEkvXejeP9W7WpxmOSBpu+3X2D5b0tWS7mhwXADAlEavzJO8YPvDku7Ryl8OtyU5PHoyAMDU\nmpwzT3K3pDe0OBYAYHbcAQoABRBzACiAmANAAcQcAAog5gBQADEHgAKIOQAUQMwBoABiDgAFEHMA\nKICYA0ABC/555ucs9uNa2nZt7wlGuezAd3qPMMpNr07vEcZ55tO9J0BxrMwBoABiDgAFEHMAKICY\nA0ABxBwACiDmAFAAMQeAAog5ABRAzAGgAGIOAAUQcwAogJgDQAHEHAAKIOYAUAAxB4ACiDkAFDAq\n5rbfZ/tHtl+wfUmroQAAsxm7Mj8k6b2S7m8wCwBgnUb92rgkP5Ek224zDgBgPThnDgAFTFyZ294n\n6fzVL0mKpBuSfHu2j9u36vHrJP3ObG8HgPKWh202E2OeZOfsw5xKw0MBQElLw3bSdN+SbHmahfPm\nANDJ2EsTr7L9tKS3S/qO7bvajAUAmMXYq1lul3R7o1kAAOvE1SwAUAAxB4ACiDkAFEDMAaAAYg4A\nBRBzACjASRbzQXa0dTGfNRef7T3ASPf2HmCkvZ/pPcFI/9d7AGxYNynJxJsyWZkDQAHEHAAKIOYA\nUAAxB4ACiDkAFEDMAaAAYg4ABRBzACiAmANAAcQcAAog5gBQADEHgAKIOQAUQMwBoABiDgAFEHMA\nKICYA0ABxBwACiDmAFAAMQeAAog5ABQwKua2b7F92PZB29+0fW6rwQAA0xu7Mr9H0huTXCzpiKSP\njx8JADCrUTFPcm+SE8PThyRtGz8SAGBWLc+Zf1DSXQ2PBwCY0uZJO9jeJ+n81S9JiqQbknx72OcG\nSceT7JnLlACANU2MeZKda/172x+Q9B5Jl038tOd3v/j4rB3S5h0T3wIAZ5blYZvNxJivxfYuSR+T\n9M4kz098w5bdYz4OAM4AS8N20v1TvWvsOfPPSdoqaZ/tR2z/w8jjAQDWYdTKPMnvthoEALB+3AEK\nAAWMWpnPbCNfhX7Nl3pPMNJy7wEAzBErcwAogJgDQAHEHAAKIOYAUAAxB4ACiDkAFEDMAaAAYg4A\nBRBzACiAmANAAcQcAAog5gBQADEHgAKIOQAUQMwBoABiDgAFEHMAKICYA0ABxBwACiDmAFAAMQeA\nAog5ABRAzAGgAGIOAAUQcwAogJgDQAGjYm77b23/0Pajtu+2/apWgwEApjd2ZX5LkjcneYukf5J0\nY4OZNqgneg8wZ8u9B5ij5d4DzNly7wHmbLn3AKeFUTFPcmzV01dKOjFunI2MmG9cy70HmLPl3gPM\n2XLvAU4Lm8cewPanJP25pP+S9IejJwIAzGziytz2PtuPrdoODf/8Y0lK8tdJLpT0NUkfmffAAIBf\n5yRtDmS/WtKdSd50in/f5oMA4AyTxJP2GXWaxfb2JP8+PL1K0uExwwAA1mfUytz2Xkmv18o3Pp+S\ndE2S/2w0GwBgSs1OswAA+lnoHaCVbzKyfYvtw7YP2v6m7XN7z9SS7ffZ/pHtF2xf0nueVmzvsv2E\n7SdtX997npZs32b7WduP9Z5lHmxvs32f7R8PF2Zc13umVmxvsf3w0MpDtifew7PQlbntrSevTbf9\nEUkXJbl2YQPMke13SbovyQnbN0tKko/3nqsV22/Qyum0z0v6qySPdB5pNNubJD0p6XJJ/yHpgKSr\nk5S4acD2OyQdk/SPSX6/9zytDYvBVyU5aHurpB9IurLQn98rkjxn+yxJD0q6Lsn3T7X/QlfmlW8y\nSnJvkpNfz0OStvWcp7UkP0lyRFKlb2S/TdKRJE8lOS7p65Ku7DxTM0kekPSL3nPMS5KjSQ4Oj49p\n5QKMC/pO1U6S54aHW7RyscqaK++F/6At25+y/VNJ75f0yUV//oJ8UNJdvYfARBdIenrV82dUKAZn\nEttLki6W9HDfSdqxvcn2o5KOStqX5MBa+zePeeWbjCZ9bcM+N0g6nmRPx1HXZZqvDzjdDKdY9kr6\n6K/83/+GluTE8HOvtkn6A9sXrbX/6Nv5X2aAnVPuukfSnZJ2t55hXiZ9bbY/IOk9ki5byECNzfBn\nV8XPJF246vm24TVsELY3ayXkX0nyrd7zzEOS/7H9z5J2SXr8VPst+mqW7auernmT0UZje5ekj0n6\nkyTP955nzqqcNz8gabvt19g+W9LVku7oPFNrVp0/r5fzBUmPJ7m19yAt2T7P9m8Oj8+RtFMTfprf\noq9mKXuTke0jks6W9PPhpYeSfKjjSE3ZvkrS5ySdp5UfqnYwyR/1nWq84S/hW7WysLktyc2dR2rG\n9h5JOyT9lqRnJd2Y5Itdh2rI9qWSvifpkFa+ORhJn0hyd9fBGrD9Jklf1sp/l5skfSPJp9d8DzcN\nAcDGx6+NA4ACiDkAFEDMAaAAYg4ABRBzACiAmANAAcQcAAog5gBQwP8D7lWIFxFyTw8AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fe7dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix Plot to visualize predictions vs. outcome\n",
    "\n",
    "# x-axis: Actual outcome\n",
    "# y-axis: Expected score (EXP)\n",
    "plt_x = np.array((feats_import.iloc[:3000,-5].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,))).tolist())\n",
    "plt_y = np.array(map(np.round, map(exp_score, predictions)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.hist2d(plt_x, plt_y, bins=2*cutoff_GD+1, range=np.array([(-cutoff_GD,cutoff_GD), (-cutoff_GD,cutoff_GD)]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success identifying H, D, A is 87.23 percent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>EXP</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTGD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>790</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>92</td>\n",
       "      <td>557</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "EXP   -1.0   0.0   1.0\n",
       "FTGD                  \n",
       "-1.0   790   111     1\n",
       " 0.0    92   557    93\n",
       " 1.0     3    83  1270"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Tabulation for Away-Win (-1), Draw (0) or Home-win (1)\n",
    "performance_df = pd.concat([\n",
    "        feats_import.iloc[:3000,-5].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)),\n",
    "        pd.Series(data=map(np.round, map(exp_score, predictions)), name='EXP', index=feats_import.iloc[:3000].index)], axis=1)\n",
    "success_res_df = pd.crosstab(performance_df.loc[:, \"FTGD\"].apply(np.sign), performance_df.loc[:, \"EXP\"].apply(np.sign))\n",
    "print \"Success identifying H, D, A is \" + str(round(100* np.trace(success_res_df)/3000.,2)) + \" percent\"\n",
    "success_res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success identifying GD is 68.4 percent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>EXP</th>\n",
       "      <th>-3.0</th>\n",
       "      <th>-2.0</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTGD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-3.0</th>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>16</td>\n",
       "      <td>154</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>241</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>557</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>446</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>242</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "EXP   -3.0  -2.0  -1.0  -0.0   1.0   2.0   3.0\n",
       "FTGD                                          \n",
       "-3.0    92    77     6     1     0     0     0\n",
       "-2.0    16   154    86    11     0     0     0\n",
       "-1.0     1   117   241    99     1     0     0\n",
       " 0.0     0     6    86   557    90     2     1\n",
       " 1.0     0     0     3    83   446    62     3\n",
       " 2.0     0     0     0     0   114   242    53\n",
       " 3.0     0     0     0     0     1    29   320"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Tabulation for exact goal differential\n",
    "\n",
    "success_df = pd.crosstab(performance_df.loc[:, \"FTGD\"], performance_df.loc[:, \"EXP\"])#, margins=True)\n",
    "exp_min = int(performance_df.loc[:, \"EXP\"].min())\n",
    "exp_max = int(performance_df.loc[:, \"EXP\"].max())\n",
    "print \"Success identifying GD is \" + str(round(np.sum([100*success_df.ix[i,i] for i in range(exp_min,exp_max+1)])/3000.,2)) + \" percent\"\n",
    "success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
