{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def moveSibling(tag, number):\n",
    "\ti = 1\n",
    "\twhile i <= number:\n",
    "\t\ttag = tag.nextSibling\n",
    "\t\ti += 1\n",
    "\treturn tag\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_dl = 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A'\n",
    "downloaded_df = pd.DataFrame(data=None, columns=columns_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in range(2006, 2017):\n",
    "    y1 = str(year)[2:]\n",
    "    y2 = str(year+1)[2:]\n",
    "    url = \"http://www.football-data.co.uk/mmz4281/\" + y1 + y2 + \"/D1.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.loc[:, columns_dl]\n",
    "    downloaded_df = downloaded_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonlist = [2006 + (i+1)/(9*34) for i in range(len(downloaded_df))]\n",
    "gamedaylist = [1 + np.mod(i/9,34) for i in range(len(downloaded_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloaded_df.loc[:, \"Season\"] = seasonlist\n",
    "downloaded_df.loc[:, \"Gameday\"] = gamedaylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teamlist = downloaded_df.loc[:, \"HomeTeam\"].unique()\n",
    "data = np.array([range(len(teamlist)), teamlist]).T\n",
    "team_df = pd.DataFrame(data=data, columns=['TID', 'team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_df = pd.merge(team_df, downloaded_df, how='inner', left_on='team', right_on='HomeTeam')\n",
    "cleaned_df = pd.merge(team_df, cleaned_df, how='inner', left_on='team', right_on='AwayTeam', suffixes=('_A', '_H'))\n",
    "\n",
    "columns_cl = ['Season', 'Gameday', 'TID_H', 'TID_A', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n",
    "cleaned_df = cleaned_df.loc[:, columns_cl].sort_values(['Season', 'Gameday'])\n",
    "cleaned_df.index = range(len(cleaned_df))\n",
    "\n",
    "cleaned_df.to_csv('Bundesliga_Data_2006_2016.csv', index=False)\n",
    "team_df = team_df.set_index('TID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "website = requests.get(\"http://www.kicker.de/news/fussball/bundesliga/spieltag/1-bundesliga/2015-16/30/2855445/spielanalyse_1-fsv-mainz-05-30_1-fc-koeln-16.html\")\n",
    "main = BeautifulSoup(website.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(str(year) + \"_\" + str(gameday) + \"_main.html\", 'w') as file:\n",
    "    file.write((main.encode('ISO-8859-1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005 1\n",
      "2005 2\n",
      "2005 3\n",
      "2005 4\n",
      "2005 5\n",
      "2005 6\n",
      "2005 7\n",
      "2005 8\n",
      "2005 9\n",
      "2005 10\n",
      "2005 11\n",
      "2005 12\n",
      "2005 13\n",
      "2005 14\n",
      "2005 15\n",
      "2005 16\n",
      "2005 17\n",
      "2005 18\n",
      "2005 19\n",
      "2005 20\n",
      "2005 21\n",
      "2005 22\n",
      "2005 23\n",
      "2005 24\n",
      "2005 25\n",
      "2005 26\n",
      "2005 27\n",
      "2005 28\n",
      "2005 29\n",
      "2005 30\n",
      "2005 31\n",
      "2005 32\n",
      "2005 33\n",
      "2005 34\n",
      "2006 1\n",
      "2006 2\n",
      "2006 3\n",
      "2006 4\n",
      "2006 5\n",
      "2006 6\n",
      "2006 7\n",
      "2006 8\n",
      "2006 9\n",
      "2006 10\n",
      "2006 11\n",
      "2006 12\n",
      "2006 13\n",
      "2006 14\n",
      "2006 15\n",
      "2006 16\n",
      "2006 17\n",
      "2006 18\n",
      "2006 19\n",
      "2006 20\n",
      "2006 21\n",
      "2006 22\n",
      "2006 23\n",
      "2006 24\n",
      "2006 25\n",
      "2006 26\n",
      "2006 27\n",
      "2006 28\n",
      "2006 29\n",
      "2006 30\n",
      "2006 31\n",
      "2006 32\n",
      "2006 33\n",
      "2006 34\n",
      "2007 1\n",
      "2007 2\n",
      "2007 3\n",
      "2007 4\n",
      "2007 5\n",
      "2007 6\n",
      "2007 7\n",
      "2007 8\n",
      "2007 9\n",
      "2007 10\n",
      "2007 11\n",
      "2007 12\n",
      "2007 13\n",
      "2007 14\n",
      "2007 15\n",
      "2007 16\n",
      "2007 17\n",
      "2007 18\n",
      "2007 19\n",
      "2007 20\n",
      "2007 21\n",
      "2007 22\n",
      "2007 23\n",
      "2007 24\n",
      "2007 25\n",
      "2007 26\n",
      "2007 27\n",
      "2007 28\n",
      "2007 29\n",
      "2007 30\n",
      "2007 31\n",
      "2007 32\n",
      "2007 33\n",
      "2007 34\n",
      "2008 1\n",
      "2008 2\n",
      "2008 3\n",
      "2008 4\n",
      "2008 5\n",
      "2008 6\n",
      "2008 7\n",
      "2008 8\n",
      "2008 9\n",
      "2008 10\n",
      "2008 11\n",
      "2008 12\n",
      "2008 13\n",
      "2008 14\n",
      "2008 15\n",
      "2008 16\n",
      "2008 17\n",
      "2008 18\n",
      "2008 19\n",
      "2008 20\n",
      "2008 21\n",
      "2008 22\n",
      "2008 23\n",
      "2008 24\n",
      "2008 25\n",
      "2008 26\n",
      "2008 27\n",
      "2008 28\n",
      "2008 29\n",
      "2008 30\n",
      "2008 31\n",
      "2008 32\n",
      "2008 33\n",
      "2008 34\n",
      "2009 1\n",
      "2009 2\n",
      "2009 3\n",
      "2009 4\n",
      "2009 5\n",
      "2009 6\n",
      "2009 7\n",
      "2009 8\n",
      "2009 9\n",
      "2009 10\n",
      "2009 11\n",
      "2009 12\n",
      "2009 13\n",
      "2009 14\n",
      "2009 15\n",
      "2009 16\n",
      "2009 17\n",
      "2009 18\n",
      "2009 19\n",
      "2009 20\n",
      "2009 21\n",
      "2009 22\n",
      "2009 23\n",
      "2009 24\n",
      "2009 25\n",
      "2009 26\n",
      "2009 27\n",
      "2009 28\n",
      "2009 29\n",
      "2009 30\n",
      "2009 31\n",
      "2009 32\n",
      "2009 33\n",
      "2009 34\n",
      "2010 1\n",
      "2010 2\n",
      "2010 3\n",
      "2010 4\n",
      "2010 5\n",
      "2010 6\n",
      "2010 7\n",
      "2010 8\n",
      "2010 9\n",
      "2010 10\n",
      "2010 11\n",
      "2010 12\n",
      "2010 13\n",
      "2010 14\n",
      "2010 15\n",
      "2010 16\n",
      "2010 17\n",
      "2010 18\n",
      "2010 19\n",
      "2010 20\n",
      "2010 21\n",
      "2010 22\n",
      "2010 23\n",
      "2010 24\n",
      "2010 25\n",
      "2010 26\n",
      "2010 27\n",
      "2010 28\n",
      "2010 29\n",
      "2010 30\n",
      "2010 31\n",
      "2010 32\n",
      "2010 33\n",
      "2010 34\n",
      "2011 1\n",
      "2011 2\n",
      "2011 3\n",
      "2011 4\n",
      "2011 5\n",
      "2011 6\n",
      "2011 7\n",
      "2011 8\n",
      "2011 9\n",
      "2011 10\n",
      "2011 11\n",
      "2011 12\n",
      "2011 13\n",
      "2011 14\n",
      "2011 15\n",
      "2011 16\n",
      "2011 17\n",
      "2011 18\n",
      "2011 19\n",
      "2011 20\n",
      "2011 21\n",
      "2011 22\n",
      "2011 23\n",
      "2011 24\n",
      "2011 25\n",
      "2011 26\n",
      "2011 27\n",
      "2011 28\n",
      "2011 29\n",
      "2011 30\n",
      "2011 31\n",
      "2011 32\n",
      "2011 33\n",
      "2011 34\n",
      "2012 1\n",
      "2012 2\n",
      "2012 3\n",
      "2012 4\n",
      "2012 5\n",
      "2012 6\n",
      "2012 7\n",
      "2012 8\n",
      "2012 9\n",
      "2012 10\n",
      "2012 11\n",
      "2012 12\n",
      "2012 13\n",
      "2012 14\n",
      "2012 15\n",
      "2012 16\n",
      "2012 17\n",
      "2012 18\n",
      "2012 19\n",
      "2012 20\n",
      "2012 21\n",
      "2012 22\n",
      "2012 23\n",
      "2012 24\n",
      "2012 25\n",
      "2012 26\n",
      "2012 27\n",
      "2012 28\n",
      "2012 29\n",
      "2012 30\n",
      "2012 31\n",
      "2012 32\n",
      "2012 33\n",
      "2012 34\n",
      "2013 1\n",
      "2013 2\n",
      "2013 3\n",
      "2013 4\n",
      "2013 5\n",
      "2013 6\n",
      "2013 7\n",
      "2013 8\n",
      "2013 9\n",
      "2013 10\n",
      "2013 11\n",
      "2013 12\n",
      "2013 13\n",
      "2013 14\n",
      "2013 15\n",
      "2013 16\n",
      "2013 17\n",
      "2013 18\n",
      "2013 19\n",
      "2013 20\n",
      "2013 21\n",
      "2013 22\n",
      "2013 23\n",
      "2013 24\n",
      "2013 25\n",
      "2013 26\n",
      "2013 27\n",
      "2013 28\n",
      "2013 29\n",
      "2013 30\n",
      "2013 31\n",
      "2013 32\n",
      "2013 33\n",
      "2013 34\n",
      "2014 1\n",
      "2014 2\n",
      "2014 3\n",
      "2014 4\n",
      "2014 5\n",
      "2014 6\n",
      "2014 7\n",
      "2014 8\n",
      "2014 9\n",
      "2014 10\n",
      "2014 11\n",
      "2014 12\n",
      "2014 13\n",
      "2014 14\n",
      "2014 15\n",
      "2014 16\n",
      "2014 17\n",
      "2014 18\n",
      "2014 19\n",
      "2014 20\n",
      "2014 21\n",
      "2014 22\n",
      "2014 23\n",
      "2014 24\n",
      "2014 25\n",
      "2014 26\n",
      "2014 27\n",
      "2014 28\n",
      "2014 29\n",
      "2014 30\n",
      "2014 31\n",
      "2014 32\n",
      "2014 33\n",
      "2014 34\n",
      "2015 1\n",
      "2015 2\n",
      "2015 3\n",
      "2015 4\n",
      "2015 5\n",
      "2015 6\n",
      "2015 7\n",
      "2015 8\n",
      "2015 9\n",
      "2015 10\n",
      "2015 11\n",
      "2015 12\n",
      "2015 13\n",
      "2015 14\n",
      "2015 15\n",
      "2015 16\n",
      "2015 17\n",
      "2015 18\n",
      "2015 19\n",
      "2015 20\n",
      "2015 21\n",
      "2015 22\n",
      "2015 23\n",
      "2015 24\n",
      "2015 25\n",
      "2015 26\n",
      "2015 27\n",
      "2015 28\n",
      "2015 29\n",
      "2015 30\n",
      "2015 31\n",
      "2015 32\n",
      "2015 33\n",
      "2015 34\n",
      "2016 1\n",
      "2016 2\n",
      "2016 3\n",
      "2016 4\n",
      "2016 5\n",
      "2016 6\n",
      "2016 7\n",
      "2016 8\n",
      "2016 9\n",
      "2016 10\n",
      "2016 11\n",
      "2016 12\n",
      "2016 13\n",
      "2016 14\n",
      "2016 15\n",
      "2016 16\n"
     ]
    }
   ],
   "source": [
    "for year in range(2005, 2017):\n",
    "    for gameday in range(1,35):\n",
    "        print year, gameday\n",
    "        url = \"http://www.kicker.de/news/fussball/bundesliga/spieltag/1-bundesliga/\"\n",
    "        url = url + str(year) + \"-\" + str(year+1)[2:4] + \"/\"\n",
    "        url = url + str(gameday) + \"/0/spieltag.html\"\n",
    "\n",
    "        website = requests.get(url)\n",
    "        main = BeautifulSoup(website.content, 'html.parser')\n",
    "        main_table = main.find('table', {'class': 'tStat', 'summary': 'Tabelle'})\n",
    "\n",
    "        # Once we get to the unplayed gamedays, no table will be displayed, and the loop shall end.\n",
    "        try:\n",
    "            main_standings = main_table.find_all('a', {'class': 'link verinsLinkBild'})\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        main_matches = main.find('table', {'class': 'tStat tab1-bundesliga', 'summary': 'Begegnungen'})\n",
    "\n",
    "        # Find all links of class \"link.\" These refer to the game analyses.\n",
    "        for game in main_matches.find_all('a', {'class' : 'link'}):\n",
    "            # result = game.parent.previous_sibling.previous_sibling.text\n",
    "            # result = map(int, result[0:result.find(\"(\")-1].split(\":\"))\n",
    "\n",
    "            game_url = game.get('href')\n",
    "            encoded_in_url = game_url.split(\"/\")\n",
    "\n",
    "            # Game ID is the article ID for kicker, as unique ID for game\n",
    "            game_id = encoded_in_url[8][0:7]\n",
    "\n",
    "            # Game URL encodes the teams which are playing\n",
    "            teams = encoded_in_url[9][13:-5].split(\"_\")\n",
    "            teams = map(int, [teams[i][teams[i].rfind('-')+1:] for i in range(2)])\n",
    "\n",
    "            # URL to open individiual games\n",
    "            game_url = \"http://www.kicker.de\" + game_url\n",
    "\n",
    "            error_count = 0\n",
    "            while error_count < 3:\n",
    "                try:\n",
    "                    game_file = requests.get(game_url)\n",
    "                    game_soup = BeautifulSoup(game_file.content, 'html.parser')\n",
    "                    filename = str(year) + \"_\"\n",
    "                    filename += (\"0\" + str(gameday))[-2:] + \"_\" \n",
    "                    filename += str(teams[0]) + \"-v-\" + str(teams[1])\n",
    "                    \n",
    "                    with open(\"game_reports/\" + filename + \"_main.html\", 'w') as file:\n",
    "                        file.write(game_soup.encode('ISO-8859-1'))\n",
    "                        break\n",
    "                except:\n",
    "                    error_count += 1\n",
    "\n",
    "            if error_count == 3:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    kicker_grades_df = pd.read_csv('Grades_2005_2016.csv')\n",
    "except:\n",
    "    if input('Re-download? yes?') == 'yes':\n",
    "        grade_row = []\n",
    "        for year in range(2005, 2017):\n",
    "            for gameday in range(1,35):\n",
    "                print year, gameday\n",
    "                url = \"http://www.kicker.de/news/fussball/bundesliga/spieltag/1-bundesliga/\"\n",
    "                url = url + str(year) + \"-\" + str(year+1)[2:4] + \"/\"\n",
    "                url = url + str(gameday) + \"/0/spieltag.html\"\n",
    "\n",
    "                website = requests.get(url)\n",
    "                main = BeautifulSoup(website.content, 'html.parser')\n",
    "                main_table = main.find('table', {'class': 'tStat', 'summary': 'Tabelle'})\n",
    "\n",
    "                # Once we get to the unplayed gamedays, no table will be displayed, and the loop shall end.\n",
    "                try:\n",
    "                    main_standings = main_table.find_all('a', {'class': 'link verinsLinkBild'})\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                # If we didn't break, proceed as usual.\n",
    "\n",
    "                main_matches = main.find('table', {'class': 'tStat tab1-bundesliga', 'summary': 'Begegnungen'})\n",
    "\n",
    "                # Find all links of class \"link.\" These refer to the game analyses.\n",
    "                for game in main_matches.find_all('a', {'class' : 'link'}):\n",
    "                    # result = game.parent.previous_sibling.previous_sibling.text\n",
    "                    # result = map(int, result[0:result.find(\"(\")-1].split(\":\"))\n",
    "\n",
    "                    game_url = game.get('href')\n",
    "                    encoded_in_url = game_url.split(\"/\")\n",
    "\n",
    "                    # Game ID is the article ID for kicker, as unique ID for game\n",
    "                    game_id = encoded_in_url[8][0:7]\n",
    "\n",
    "                    # Game URL encodes the teams which are playing\n",
    "                    teams = encoded_in_url[9][13:-5].split(\"_\")\n",
    "                    teams = map(int, [teams[i][teams[i].rfind('-')+1:] for i in range(2)])\n",
    "\n",
    "                    # URL to open individiual games\n",
    "                    game_url = \"http://www.kicker.de\" + game_url\n",
    "                    error_count = 0\n",
    "                    while error_count < 10:\n",
    "                        try:\n",
    "                            game_file = requests.get(game_url)\n",
    "                            game_soup = BeautifulSoup(game_file.content, 'html.parser')\n",
    "                            game_soup.find('table', {'class': 'tStat', 'summary': 'Vereinsliste'}).find_all('div', {'class': 'aufstellung_team'})\n",
    "                            break\n",
    "                        except:\n",
    "                            error_count += 1\n",
    "\n",
    "                    if error_count == 10:\n",
    "                        continue\n",
    "\n",
    "                    i = 0\n",
    "                    for lineup in game_soup.find('table', {'class': 'tStat', 'summary': 'Vereinsliste'}).find_all('div', {'class': 'aufstellung_team'}):\n",
    "                        no_players = 0\n",
    "                        grade = 0.\n",
    "                        for player in lineup.find_all('a'):\n",
    "                            grade_raw = unicode(player.next_sibling)\n",
    "\n",
    "                            grade_del1 = unicode(grade_raw).find('(')\n",
    "                            grade_del2 = unicode(grade_raw).find(')')\n",
    "\n",
    "                            if grade_del1 == -1:\n",
    "                                continue\n",
    "\n",
    "                            grade += float(grade_raw[grade_del1+1:grade_del2].replace(\",\", \".\"))\n",
    "\n",
    "                            no_players += 1\n",
    "                            if no_players == 11:\n",
    "                                break\n",
    "                        grade = grade/no_players\n",
    "\n",
    "                        grade_row += [[year, gameday, teams[np.mod(i,2)], grade]]\n",
    "                        i += 1\n",
    "    else:\n",
    "        \"Doing nothing. No df loaded.\"\n",
    "\n",
    "try:\n",
    "    kicker_grades_df = kicker_grades_df.drop('Unnamed: 0', axis=1)\n",
    "except:\n",
    "    print \"Import Successful\"\n",
    "\n",
    "kicker_grades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kicker_grades_df.to_csv('Grades_2005_2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_list = []\n",
    "for year in range(2005,2017):\n",
    "    url = 'http://www.kicker.de/news/fussball/bundesliga/vereine/1-bundesliga/'\n",
    "    url += str(year) + '-' + str(year+1)[-2:]\n",
    "    url += '/vereine-liste.html'\n",
    "\n",
    "    website = requests.get(url)\n",
    "    main = BeautifulSoup(website.content, 'html.parser')\n",
    "    for team in main.find_all('a', {'class': 'link verinsLinkBild'}):\n",
    "        team_name_id = team.get('href').split('/')[7]\n",
    "        team_name = team_name_id[0:team_name_id.rfind(\"-\")]\n",
    "        team_id = team_name_id[team_name_id.rfind(\"-\")+1:]\n",
    "        team_list += [[int(team_id), team_name]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kicker_team_df = pd.DataFrame(data=team_list, columns=['KID', 'KName'])\n",
    "kicker_team_df = kicker_team_df.drop_duplicates().set_index('KID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_df = pd.read_csv('Team_ID_hardcoded.csv')\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rescale_grade(x):\n",
    "    return 1 - (x-1.)/5\n",
    "\n",
    "grades_df = kicker_grades_df.merge(key_df, how='left', left_on='KID', right_on='KID').loc[:, ('Season', 'Gameday','TID', 'GradeAvg')]\n",
    "grades_df = grades_df.set_index(['TID', 'Season', 'Gameday']).sort_index()\n",
    "grades_df = grades_df.apply(rescale_grade)\n",
    "\n",
    "print grades_df.loc[:, 'GradeAvg'].min()\n",
    "print grades_df.loc[:, 'GradeAvg'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inverse(x):\n",
    "    return 1./x\n",
    "def points(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 1./3\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df = cleaned_df.merge(grades_df, how='inner', left_on=['TID_H', 'Season', 'Gameday'], right_index=True)\n",
    "complete_df = complete_df.merge(grades_df, how='inner', left_on=['TID_A', 'Season', 'Gameday'], right_index=True)\n",
    "\n",
    "complete_df = complete_df.rename(columns={'GradeAvg_x': 'HGA', 'GradeAvg_y': 'AGA'})\n",
    "complete_df = complete_df.replace({'H':1, 'D':0.5, 'A':0})\n",
    "complete_df.loc[:, 'FTGD'] = complete_df.loc[:, 'FTHG'] - complete_df.loc[:, 'FTAG']\n",
    "complete_df.loc[:, 'HTGD'] = complete_df.loc[:, 'HTHG'] - complete_df.loc[:, 'HTAG']\n",
    "\n",
    "complete_df.loc[:, 'Odds'] = (complete_df.filter(regex='^B365').apply(inverse)*(1,0.5,0)).apply(np.sum, axis=1)\n",
    "\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tid=0\n",
    "\n",
    "query = 'TID_H == ' + str(tid)\n",
    "temp_H = complete_df.query(query).loc[:, ['TID_H', 'Season', 'Gameday', 'FTHG', 'FTAG']]\n",
    "temp_H.loc[:, 'Gameday'] += 1\n",
    "temp_H.loc[:, 'GD'] = temp_H.loc[:, 'FTHG'] - temp_H.loc[:, 'FTAG']\n",
    "temp_H = temp_H.set_index(['TID_H', 'Season', 'Gameday'])\n",
    "\n",
    "query = 'TID_A == ' + str(tid)\n",
    "temp_A = complete_df.query(query).loc[:, ['TID_A', 'Season', 'Gameday', 'FTHG', 'FTAG']]\n",
    "temp_A.loc[:, 'Gameday'] += 1\n",
    "temp_A.loc[:, 'GD'] = - temp_A.loc[:, 'FTHG'] + temp_A.loc[:, 'FTAG']\n",
    "temp_A = temp_A.set_index(['TID_A', 'Season', 'Gameday'])\n",
    "\n",
    "temp = pd.concat([temp_H, temp_A]).sort_index()\n",
    "temp.index = temp.index.rename(['TID', 'Season', 'Gameday'])\n",
    "temp.loc[:, 'Points'] = temp.loc[:, 'GD'].apply(points).to_frame()\n",
    "\n",
    "temp = temp.drop(['FTHG', 'FTAG'], axis=1)\n",
    "\n",
    "table_df = temp.groupby(level=['TID', 'Season'], group_keys=False).cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_index = pd.MultiIndex(levels=[[],[],[]],\n",
    "                             labels=[[],[],[]],\n",
    "                             names=[u'TID', u'Season', u'Gameday'])\n",
    "running_df = pd.DataFrame(data=None, columns=['Points'], index=multi_index)\n",
    "\n",
    "for tid in range(len(key_df)):\n",
    "    query = 'TID_H == ' + str(tid)\n",
    "    temp_H = complete_df.query(query).loc[:, ['TID_H', 'Season', 'Gameday', 'FTHG', 'FTAG']]\n",
    "    temp_H.loc[:, 'Gameday'] += 1\n",
    "    temp_H.loc[:, 'GD'] = temp_H.loc[:, 'FTHG'] - temp_H.loc[:, 'FTAG']\n",
    "    temp_H = temp_H.set_index(['TID_H', 'Season', 'Gameday'])\n",
    "\n",
    "    query = 'TID_A == ' + str(tid)\n",
    "    temp_A = complete_df.query(query).loc[:, ['TID_A', 'Season', 'Gameday', 'FTHG', 'FTAG']]\n",
    "    temp_A.loc[:, 'Gameday'] += 1\n",
    "    temp_A.loc[:, 'GD'] = - temp_A.loc[:, 'FTHG'] + temp_A.loc[:, 'FTAG']\n",
    "    temp_A = temp_A.set_index(['TID_A', 'Season', 'Gameday'])\n",
    "\n",
    "    temp = pd.concat([temp_H, temp_A]).sort_index()\n",
    "    temp.index = temp.index.rename(['TID', 'Season', 'Gameday'])\n",
    "    temp = temp.loc[:, 'GD'].apply(points).rename('Points').to_frame()\n",
    "    \n",
    "    running_df = running_df.append(temp.groupby(level=['TID', 'Season'], group_keys=False).rolling(3, 1).mean())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_df.to_csv('Running_Points_2006_2013.csv')\n",
    "len(running_df)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_running_df = complete_df.merge(running_df, how='left', left_on=['TID_H', 'Season', 'Gameday'], right_index=True)\n",
    "complete_running_df = complete_running_df.merge(running_df, how='left', left_on=['TID_A', 'Season', 'Gameday'], right_index=True)\n",
    "\n",
    "complete_running_df = complete_running_df.rename(columns={'Points_x': 'HP3', 'Points_y': 'AP3'}).filter(regex='^(?!B365)')\n",
    "complete_running_df = complete_running_df.drop(['FTAG', 'FTR','HTAG', 'HTR'], axis=1)\n",
    "\n",
    "complete_running_df = complete_running_df.drop_duplicates(['Season', 'Gameday', 'TID_H', 'TID_A']).fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_running_df.to_csv('All_Data_2006_2016.csv')\n",
    "len(complete_running_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complete_running_df.fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print complete_running_df.loc[:, ['HST', 'AST', 'HS', 'AS']].mean()\n",
    "print 5.57/14.61\n",
    "print 4.49/11.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shots = complete_running_df.loc[:, ['TID_H','Season', 'HST', 'AST', 'HS', 'AS']].groupby(['TID_H', 'Season']).mean()\n",
    "conversion_df = shots\n",
    "conversion_df.loc[:, 'HEff'] = np.round(100*conversion_df.loc[:, 'HST'] / conversion_df.loc[:, 'HS'], 1)\n",
    "conversion_df.loc[:, 'AEff'] = np.round(100*conversion_df.loc[:, 'AST'] / conversion_df.loc[:, 'AS'], 1)\n",
    "\n",
    "print conversion_df.loc[:, ['HEff', 'AEff']].mean()\n",
    "#conversion_df.index = conversion_df.set_index(range(len(conversion_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoff_GD = 2\n",
    "print complete_running_df.query('TID_H == 30').loc[:, 'FTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)).value_counts(False, False, True)\n",
    "print (-complete_running_df.query('TID_A == 30').loc[:, 'FTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,))).value_counts(False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shots = complete_running_df.loc[:, ['TID_A', 'HST', 'AST', 'HS', 'AS']].groupby('TID_A').mean()\n",
    "conversion_df = shots.merge(team_df, left_index=True, right_index=True).set_index('team')\n",
    "conversion_df.loc[:, 'HEff'] = np.round(100*conversion_df.loc[:, 'HST'] / conversion_df.loc[:, 'HS'], 1)\n",
    "conversion_df.loc[:, 'AEff'] = np.round(100*conversion_df.loc[:, 'AST'] / conversion_df.loc[:, 'AS'], 1)\n",
    "\n",
    "print conversion_df.loc[:, ['HEff', 'AEff']].mean()\n",
    "conversion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.plot(kind='scatter', x='HGA', y='FTGD')\n",
    "complete_df.plot(kind='scatter', x='AGA', y='FTGD')\n",
    "complete_running_df.plot.hexbin(x='HGA', y='AGA', gridsize=20)\n",
    "complete_running_df.plot.hexbin(x='HGA', y='AGA', C='Odds', gridsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_running_df.plot(kind='scatter', x='HP3', y='AP3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_running_df.loc[:, ['Season', 'HGA', 'AGA']].groupby('Season').mean().plot()\n",
    "complete_running_df.loc[:, ['Season', 'FTGD', 'HTGD']].groupby('Season').mean().plot()\n",
    "(complete_running_df.loc[:, ['Season', 'FTGD', 'HTGD']].groupby('Season').std()*(1,np.sqrt(2.))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_df.plot.hexbin(x='Odds', y='FTGD', gridsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
