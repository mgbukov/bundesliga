{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project (give it a fancy name!)\n",
    "\n",
    "## Goals of the Project\n",
    "\n",
    "This project presents an attempt to quantify the predictability of the Bundesliga football games based on the information contained in game statistics starting from season 2006/07 onwards. In particular,\n",
    "\n",
    "* we use a deep neural network to examine the correlations between different features provided from the statistics of individual games.\n",
    "* we ask the question: \"to what accuracy can one determine the outcome and score of any Bundesliga game, given the statistics of games from a number of previous seasons?\".\n",
    "* we compare the predictions of our model on the Bundesliga season 2016/17 up to the present matchday. We also make a prediction for the final Bundesliga table for season 2016/17.\n",
    "\n",
    "Studying the predictive power of football statistics on the outcome of games is an interesting and challenging problem of general importance both to sports, and the development of a proper intuition about the inner workings of machine learning techniques. The difficulty of the problem is enhanced by the occurence of physical outlier events in the data, for example a team performing better in a given game but nevertheless losing to their opponent 'misfortunately'. Such events, although they must be accounted for by the correct reallistic model, can easily be recognised as noise or bias by the neural network leading to an increase in both the in-sample and out-of-sample errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Features\n",
    "\n",
    "We use a manually developed football games dataset, collected from data provided at ... and kicker.de . We then modified those sets introducing some new features as combinations of the existing ones, while at the same time dropping all irrelevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape successful\n",
      "['Season' 'Gameday' 'TID_H' 'TID_A' 'FTHG' 'HTHG' 'HS' 'AS' 'HST' 'AST'\n",
      " 'HF' 'AF' 'HC' 'AC' 'HY' 'AY' 'HR' 'AR' 'HGA' 'AGA' 'FTGD' 'HTGD' 'Odds'\n",
      " 'HP3' 'AP3']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load data\n",
    "feats_import = pd.read_csv('All_Data_2006_2016.csv')\n",
    "try:\n",
    "    feats_import = feats_import.drop(['Unnamed: 0'], axis=1)\n",
    "    print \"Reshape successful\"\n",
    "except:\n",
    "    print \"Successful import\"\n",
    "    \n",
    "# Each data point is represented as a vector containing the following features:\n",
    "print feats_import.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  feature name | meaning |  feature name | meaning |  feature name | meaning |\n",
    "|---|---|---|---|---|---|\n",
    "|Season|season number|TID_H|home team ID|TID_A|away team ID|\n",
    "|Gameday|match day number|HS|home team shots|AS|away team shots|\n",
    "|HTGD|half time goal difference|HST|home team shots on target|AST|away team shots on target|\n",
    "|HTHG|half time goals scored by home team|HF|home team fouls committed|AF|away team fouls committed|\n",
    "|FTGD|-|HC|home teams corner kicks|AC|away teams corner kicks|\n",
    "|Odds|-|HY|home team yellow cards|AY|away team yellow cards|\n",
    "|HP3|-|HR|home team red cards|AR|away team red cards|\n",
    "|AP3|-| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, each feature from the data was normalised to unity with respect to all games in the data set.\n",
    "\n",
    "To acquire a better understanding of the data used to train the deep neural net, below we show histrograms of selected interesting features, that are often used by the experts to intuitively estimate and argue for the outcome of a particular\n",
    "\n",
    " fixture:\n",
    "\n",
    "1. Shots (again, two hists: H and A)\n",
    "\n",
    "2. Shots on target (let's plot the two hists (H and A) on top of each other with some transparency)\n",
    "\n",
    "3. Attendance\n",
    "\n",
    "4. 5, 6...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Datasets\n",
    "\n",
    "Using the data points discussed above, we now put together a training and a test data set as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Deep Neural Network\n",
    "\n",
    "Our model is a deep relu neural net with the following architecture (consider putting table horizontally?):\n",
    "\n",
    "|layer|number of relu neurons\n",
    "|---|---|\n",
    "|input | ? |\n",
    "|hidden 1| 50 |\n",
    "|hidden 2| 500|\n",
    "|hidden 3| 500|\n",
    "|hidden 4| 50|\n",
    "|output softmax|?| \n",
    "\n",
    "We train with minibatches using the 'adam' optimiser, and minimise the categorical entropy function. Additionally, we apply 'dropout' regularisation after hidden layer 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### set up deep neural net with Keras\n",
    "# initiate model\n",
    "model = Sequential()\n",
    "# input layer\n",
    "model.add(Dense(50, input_dim=len(X[0]), init='lecun_uniform', activation='relu')) \n",
    "# hidden layer 1\n",
    "model.add(Dense(500, activation='relu'))\n",
    "# hidden layer 2\n",
    "model.add(Dense(500, activation='relu'))\n",
    "# hidden layer 3\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# hidden layer 4\n",
    "model.add(Dropout(dropout_p))\n",
    "# output layer\n",
    "model.add(Dense(2*cutoff_GD+1, activation='relu'))\n",
    "model.add(Activation('softmax'))\n",
    "### compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "\n",
    "show some plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
