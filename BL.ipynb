{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project (give it a fancy name!)\n",
    "\n",
    "## Goals of the Project\n",
    "\n",
    "This project presents an attempt to quantify the predictability of the Bundesliga football games based on the information contained in game statistics starting from season 2006/07 onwards. In particular,\n",
    "\n",
    "* we use a deep neural network to examine the correlations between different features provided from the statistics of individual games.\n",
    "* we ask the question: \"to what accuracy can one determine the outcome and score of any Bundesliga game, given the statistics of games from a number of previous seasons?\".\n",
    "* we compare the predictions of our model on the Bundesliga season 2016/17 up to the present matchday. We also make a prediction for the final Bundesliga table for season 2016/17.\n",
    "\n",
    "Studying the predictive power of football statistics on the outcome of games is an interesting and challenging problem of general importance both to sports, and the development of a proper intuition about the inner workings of machine learning techniques. The difficulty of the problem is enhanced by the occurence of physical outlier events in the data, for example a team performing better in a given game but nevertheless losing to their opponent 'misfortunately'. Such events, although they must be accounted for by the correct reallistic model, can easily be recognised as noise or bias by the neural network leading to an increase in both the in-sample and out-of-sample errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Features\n",
    "\n",
    "We use a manually developed football games dataset, collected from data provided at football-data.co.uk and kicker.de . We then modified those sets introducing some new features as combinations of the existing ones, while at the same time dropping all irrelevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape successful\n",
      "['HTGD' 'FTHG' 'HTHG' 'HGA' 'AGA' 'Attendance' 'ChancesA' 'ChancesH' 'HS'\n",
      " 'AS' 'HST' 'AST' 'HF' 'AF' 'HC' 'AC' 'HY' 'AY' 'HR' 'AR' 'HP3' 'AP3'\n",
      " 'Interval_W' 'Interval_L' 'Interval_D']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load data\n",
    "feats_import = pd.read_csv('All_Data_2006_2016.csv')\n",
    "try:\n",
    "    feats_import = feats_import.drop(['Unnamed: 0'], axis=1)\n",
    "    print \"Reshape successful\"\n",
    "except:\n",
    "    print \"Successful import\"\n",
    "    \n",
    "# Set a cutoff for the goal differential: \n",
    "# All wins/losses with more than 3 goals difference are counted as wins/losses with goal differential of 3\n",
    "cutoff_GD = 3\n",
    "GD_min = -cutoff_GD\n",
    "GD_max = +cutoff_GD\n",
    "GD_spread = GD_max-GD_min + 1\n",
    "\n",
    "# Import features and drop data which are not relevant or too specific, like teams playing. \n",
    "feats = feats_import.drop(['Season', 'Gameday', u'Link', u'TID_H', u'TID_A', u'TName_H', u'TName_A', 'Odds'], axis=1).drop('FTGD', axis=1)\n",
    "feats.loc[:, 'HTGD'] = feats_import.loc[:, 'HTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)) + cutoff_GD\n",
    "\n",
    "\n",
    "# Each data point is represented as a vector containing the following features:\n",
    "print feats.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  feature name | meaning |  feature name | meaning |  feature name | meaning |\n",
    "|---|---|---|---|---|---|\n",
    "|HTGD|half-time goal differential|FTHG|full-time home goals|HTHG|half-time home goals|\n",
    "|HGA|home team grade avg.|AGA|away team grade avg.|Attendance|Attendance in stadium, normalized to home team's max|\n",
    "|ChancesH|home team scoring opportunities|ChancesA|away team scoring opportunities|HS|home team shots|\n",
    "|AS|away team shots|HST|home team shots on target|AST|away team shots on target|\n",
    "|HF|home team fouls committed|AF|away team fouls committed|HC|home team corner kicks|\n",
    "|AC|away teams corner kicks|HY|home teams yellow cards|AY|away teams yellow cards|\n",
    "|HR|home team red cards|AR|away team red cards|HP3|home team points in last 3 games\n",
    "|AP3|away team points in last 3 games||||||\n",
    "|Interval_W|Time winning team was in the lead|Interval_L|Time losing team was in the lead|Interval_D|Time match was in a tie|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, each feature from the data was normalised to unity with respect to all games in the data set.\n",
    "\n",
    "To acquire a better understanding of the data used to train the deep neural net, below we show histrograms of selected interesting features, that are often used by the experts to intuitively estimate and argue for the outcome of a particular\n",
    "\n",
    " fixture:\n",
    "\n",
    "1. Shots (again, two hists: H and A)\n",
    "\n",
    "2. Shots on target (let's plot the two hists (H and A) on top of each other with some transparency)\n",
    "\n",
    "3. Attendance\n",
    "\n",
    "4. 5, 6...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Datasets\n",
    "\n",
    "Using the data points discussed above, we now put together a training and a test data set as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTGD</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HGA</th>\n",
       "      <th>AGA</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>ChancesA</th>\n",
       "      <th>ChancesH</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>...</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HP3</th>\n",
       "      <th>AP3</th>\n",
       "      <th>Interval_W</th>\n",
       "      <th>Interval_L</th>\n",
       "      <th>Interval_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.914316</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.881092</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HTGD  FTHG  HTHG       HGA       AGA  Attendance  ChancesA  ChancesH    HS  \\\n",
       "0   4.0   2.0   1.0  0.654545  0.381818    1.000000         7         7  12.0   \n",
       "1   2.0   1.0   0.0  0.363636  0.490909    0.914316         4         9  26.0   \n",
       "2   5.0   3.0   2.0  0.654545  0.300000    1.000000         0        10  20.0   \n",
       "3   4.0   2.0   1.0  0.527273  0.381818    0.985222         5         5  11.0   \n",
       "4   3.0   2.0   0.0  0.545455  0.427273    0.881092         6         6  13.0   \n",
       "\n",
       "     AS     ...       AC   HY   AY   HR   AR  HP3  AP3  Interval_W  \\\n",
       "0  16.0     ...      4.0  1.0  2.0  0.0  0.0  0.5  0.5    0.733333   \n",
       "1  10.0     ...      2.0  3.0  2.0  0.0  0.0  0.5  0.5    0.000000   \n",
       "2   8.0     ...      1.0  3.0  0.0  1.0  1.0  0.5  0.5    0.644444   \n",
       "3  19.0     ...      8.0  2.0  3.0  0.0  0.0  0.5  0.5    0.677778   \n",
       "4  11.0     ...      5.0  0.0  4.0  0.0  1.0  0.5  0.5    0.433333   \n",
       "\n",
       "   Interval_L  Interval_D  \n",
       "0         0.0    0.266667  \n",
       "1         0.0    1.000000  \n",
       "2         0.0    0.355556  \n",
       "3         0.0    0.322222  \n",
       "4         0.0    0.566667  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview over the data set\n",
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data set to values between 0 and 1\n",
    "norm = [GD_spread-1, 9, 5, 1, 1, 1, 22, 22, 36, 36, 36, 33, 35, 35, 20, 20, 11, 11, 4, 4, 1, 1, 1, 1, 1]\n",
    "\n",
    "feats = feats/norm\n",
    "\n",
    "# Identify the point where season 2015/16 ends and thus the most recent season begins\n",
    "season15_end = feats_import[feats_import['Season']==2016].index[0]\n",
    "\n",
    "# Create the labels for the goal differentials between -cutoff_GD and +cutoff_GD\n",
    "label = feats_import.loc[:, 'FTGD'].apply(min, args=(cutoff_GD,)).apply(max, args=(-cutoff_GD,)) + cutoff_GD\n",
    "\n",
    "# Create a set of vectors which serve as the goal differential identifier.\n",
    "ID = np.eye(GD_spread)\n",
    "\n",
    "# Bring X and y into numpy format\n",
    "X = feats.iloc[:season15_end].as_matrix()\n",
    "y_pre = map(int, label.iloc[:season15_end].as_matrix())\n",
    "y = np.array([ID[i] for i in y_pre])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Deep Neural Network\n",
    "\n",
    "Our model is a deep relu neural net with the following architecture (consider putting table horizontally?):\n",
    "\n",
    "|layer|number of relu neurons\n",
    "|---|---|\n",
    "|input | ? |\n",
    "|hidden 1| 50 |\n",
    "|hidden 2| 500|\n",
    "|hidden 3| 500|\n",
    "|hidden 4| 50|\n",
    "|output softmax|?| \n",
    "\n",
    "We train with minibatches using the 'adam' optimiser, and minimise the categorical entropy function. Additionally, we apply 'dropout' regularisation after hidden layer 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### set up deep neural net with Keras\n",
    "dropout_p = 0.4\n",
    "# initiate model\n",
    "model = Sequential()\n",
    "# input layer\n",
    "model.add(Dense(50, input_dim=len(X[0]), init='lecun_uniform', activation='relu')) \n",
    "# Dropout layer 1\n",
    "model.add(Dropout(dropout_p))\n",
    "# hidden layer 1\n",
    "model.add(Dense(500, activation='relu'))\n",
    "# hidden layer 2\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# Dropout layer 2\n",
    "model.add(Dropout(dropout_p))\n",
    "# output layer\n",
    "model.add(Dense(2*cutoff_GD+1, activation='relu'))\n",
    "model.add(Activation('softmax'))\n",
    "### compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on the training data with 100 epochs and a mini-batch size of 10. <br>\n",
    "Since we use a softmax activation, the neural network outputs probabilities for the different outcomes of goal differentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728431373591\n",
      "3008/3060 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, nb_epoch=100, batch_size=10, verbose=False)\n",
    "print model.evaluate(X, y, batch_size=10, verbose=False)[1]\n",
    "\n",
    "predictions = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.evaluate() function tests the accuracy to which the network has learned to recognize the results of a match just by the stats of said game. <br> We achieve approximately 73 percent accuracy. This result can be improved considerably by considering a smaller cutoff goal differential. In the extreme case of a cutoff of 1, the neural network only tries to learn the winner and loser or if there was a draw.\n",
    "\n",
    "We use the probabilities for the result to calculate the expected score via the function exp_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success identifying H, D, A is 98.27 percent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>EXP</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTGD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>890</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "EXP   -1.0   0.0   1.0\n",
       "FTGD                  \n",
       "-1.0   890    31     1\n",
       " 0.0     0   754     0\n",
       " 1.0     1    20  1363"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign an expected score with probabilities\n",
    "def exp_score(x):\n",
    "    multiplier = np.array(range(-cutoff_GD, cutoff_GD+1))\n",
    "    return np.sum(np.array(x) * multiplier)\n",
    "\n",
    "# Cross-Tabulation for Away-Win (-1), Draw (0) or Home-win (1)\n",
    "performance_df = pd.concat([\n",
    "        label.iloc[:season15_end] + GD_min,\n",
    "        pd.Series(data=map(np.round, map(exp_score, predictions)), name='EXP', index=label.iloc[:season15_end].index)], axis=1)\n",
    "\n",
    "success_res_df = pd.crosstab(performance_df.loc[:, \"FTGD\"].apply(np.sign), performance_df.loc[:, \"EXP\"].apply(np.sign))\n",
    "print \"Success identifying H, D, A is \" + str(round(100. * np.trace(success_res_df)/season15_end,2)) + \" percent\"\n",
    "success_res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the expected result (Win, Draw, Loss) correctly classifies the outcome of the game in 98.3 percent of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "\n",
    "luck/no luck\n",
    "\n",
    "Which features are relevant? \n",
    "\n",
    "Change outcome to -1,0,+1 and check outcome of model \n",
    "\n",
    "Plot prediction vs current table after 16 games\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
