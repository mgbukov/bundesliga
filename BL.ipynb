{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project\n",
    "\n",
    "## Goals of the Project\n",
    "\n",
    "The project studes and attempts to quantify the predictability of the Bundesliga football games based on the information contained in game statistics staring from 2006 onwards. In particular,\n",
    "\n",
    "* we use a deep neural network to examine the correlations between different features provided from the statistics of individual games\n",
    "* we ask the question to what accuracy one can determine the outcome and score of any Bundesliga game, given the game statistics.\n",
    "* based on our model, we compare the predictions of our model on the Bundesliga season 2016/17 up to present date. We also and make a prediction for final Bundesliga table for season 2016/17.\n",
    "\n",
    "Studying the predictive power on footbal statistics on the outcome of games is an interesting and challenging problem of importance both to sports in general, and the development of a proper intuition about the inner workings of machine learning techniques. The difficulty of the problem is enhanced by the occurence of outlier events in the data, for example a team performing better in a given game but nevertheless losing to their opponent due to 'luck'. These events can easily be recognised as noise or bias by the neural network leading to an increase of both the in-sample and out-of-sample error. \n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the football games dataset provided at ... We then modified the set introducing some new features as combinations of the existing ones, while dropping others.\n",
    "\n",
    "Each data point is represented as a vector containing the following features:\n",
    "\n",
    "Last, each feature from the data was normalised to unity with respect to all games in the data set.\n",
    "\n",
    "## Model: Deep Neural Network\n",
    "\n",
    "Our model is a deep neural net, consisting of an input layer, four hidden layers and an output layers:\n",
    "* input layer: ?? features\n",
    "* hidden layer 1: 50 neurons\n",
    "* hidden layer 2: 500 neurons\n",
    "* hidden layer 3: 500 neurons\n",
    "* hidden layer 4: 50 neurons\n",
    "* output layer with softmax activation: ?? features\n",
    "\n",
    "We train with minibatches using 'adam', and minimise the categorical entropy function. Additionally, we apply 'dropout' regularisation after hidden layer 4. \n",
    "\n",
    "here comes the code...\n",
    "\n",
    "## Results\n",
    "\n",
    "show some plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
